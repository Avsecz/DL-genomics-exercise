{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a DeepBind model\n",
    "\n",
    "By Ziga Avsec (Avsecz on github).\n",
    "\n",
    "Now that you have learned the basics in the previous exercise, let's have a look at the real-world example. We are going to use a set sequences at the ChIP-seq peaks of the FoxA1 transcription factor as done by DeepBind - https://www.nature.com/articles/nbt.3300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install concise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can import and directly use the convenience functions from the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Avsecz/DL-genomics-exercise/master/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluate, plot_filters, plot_history, plot_seq_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the deepbind data\n",
    "\n",
    "The raw sequneces from the ChIP-seq peaks provided in the supplementary material of the article look like this:\n",
    "\n",
    "```\n",
    "FoldID\tEventID\tseq\tBound\n",
    "A\tseq_00001_peak\tCTGAAATTGCTGTATTTACCTTGAAAACCACAAACTGTAAACAGGGCACCTGTTCAGAGAAGATCTTCAAACTGCTCACTCACTAAATCAACACCTGGGAA\t1\n",
    "A\tseq_00003_peak\tGAGGCACTGGGGCAGAACAAATTTGCACAGTGTCTGCTGTGGACATAAGGGATTTCTTCAGCCCTATGCAAATAGTAATCCCACTAGTTCCCAGAAGATAA\t1\n",
    "A\tseq_00005_peak\tCTTTTACTATTTACCTTGGCAAGTCCAGGACCGGATTGATGATCTGTAAAGTGGATTTGTTATTTGGCTGTTTGCTTTGGCAGCTCTTGAAAGCACTTTGC\t1\n",
    "A\tseq_00007_peak\tAAAACAGATGTTGCAACAAGCAAACATCTTTGTGATGACACAGTGATGTTATCGTAGCTGTATAAACAACCGTATGGCCTTTGGCCTGAGATTCCGGAAGC\t1\n",
    "A\tseq_00009_peak\tCAGTGTTTGCCCTTCCAAAGCCAGAGCCATAAAAGGCAGCTTTCAAAGTCACTGCCGCAGAAATGTCAACATGAGGGGGAGGCCAGTCATGGTTTCTGAGG\t1\n",
    "A\tseq_00011_peak\tGAGGCCCCATGCTCATTTTTTTCCTCTCCCAGAATCTCAGAAAAGTAAATAACCACCCGAGCTGCTCTAGCGGGTAAACAGCCCAGAGTTTGCTCTCCTAA\t1\n",
    "A\tseq_00013_peak\tGAGAATGGAGAGAAGCAGCTAGGCAAATAATTGGCAAGAAAAGTAAACAGTTACAGTGCAGCTTTGTTTACCCACTCTGCCTATCTGCGTTTCTGAAATTG\t1\n",
    "A\tseq_00015_peak\tTGGTTCCAAGTGTGTCAACAGCCTGTTGCTTTCTAGTTCAACAAGAGGGAATAATCTTTGGTAAACATGGCCGTTGGAAAAAAGCAAATATTTGTCTTGGC\t1\n",
    "A\tseq_00017_peak\tCCAGGAAGAAGAACGATAAAGCTTGTTGACTTTTGCTCTTTGGAGGCTATCTTTCTCCTAGCAGAGTAAACGCATCTCTAGGGGATTAAAGGCAGGCTCCA\t1\n",
    "```\n",
    "\n",
    "We are providing you the code to download, load and pre-process data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concise.preprocessing import encodeDNA\n",
    "\n",
    "def load_deepbind_data(path, shuffle=True):\n",
    "    \"\"\"Load the DeepBind data into\n",
    "    \n",
    "    Args:\n",
    "      path: path to the .seq.gz file of deebbind.\n",
    "        example: 'https://github.com/jisraeli/DeepBind/raw/master/data/encode/FOXA1_HepG2_FOXA1_(SC-101058)_HudsonAlpha_AC.seq.gz'\n",
    "    \n",
    "    Returns:\n",
    "      (one-hot-encoded array, labels)\n",
    "    \"\"\"\n",
    "    import random\n",
    "    from random import Random\n",
    "    def dincl_shuffle_string(s):\n",
    "        sl = [s[2*i:2*(i+1)] for i in range(int(np.ceil(len(s)/2)))]\n",
    "        random.shuffle(sl)\n",
    "        return \"\".join(sl)\n",
    "    \n",
    "    # Load the positive sequences\n",
    "    df = pd.read_table(path)\n",
    "    df = df[df.Bound==1]\n",
    "    pos_seq = list(df.seq)\n",
    "    \n",
    "    # Generate the negative set by permuting the sequence\n",
    "    neg_seq = [dincl_shuffle_string(s) for s in pos_seq]\n",
    "    seqs = pos_seq + neg_seq\n",
    "    labels = [1] * len(pos_seq) + [0] * len(neg_seq)\n",
    "    \n",
    "    # Permute the order\n",
    "    idx = list(range(len(seqs)))\n",
    "    if shuffle:\n",
    "        Random(42).shuffle(idx)\n",
    "        \n",
    "    return encodeDNA(seqs)[idx], np.array(labels)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_deepbind_data('https://github.com/jisraeli/DeepBind/raw/master/data/encode/FOXA1_HepG2_FOXA1_(SC-101058)_HudsonAlpha_AC.seq.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = load_deepbind_data('https://github.com/jisraeli/DeepBind/raw/master/data/encode/FOXA1_HepG2_FOXA1_(SC-101058)_HudsonAlpha_B.seq.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Your task is now to:\n",
    "- train a model\n",
    "- evaluate it\n",
    "- visualize the filters\n",
    "- visualize the importance scores\n",
    "- lookup the discovered motif\n",
    "  - Visit http://cisbp.ccbr.utoronto.ca/ and enter FoxA1 motif  \n",
    "  - Lookup other motifs on: http://meme-suite.org/tools/tomtom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
